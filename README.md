# ğŸš€ Project Name

## ğŸ“Œ Table of Contents
- [Introduction](#introduction)
- [Demo](#demo)
- [Inspiration](#inspiration)
- [What It Does](#what-it-does)
- [How We Built It](#how-we-built-it)
- [Challenges We Faced](#challenges-we-faced)
- [How to Run](#how-to-run)
- [Tech Stack](#tech-stack)
- [Team](#team)

---

## ğŸ¯ Introduction
We are trying to build an integrated platfrom support tool which assists the platform support team to address any issues, provides references to past issues and enables them to monitor applications through integrated tools like splunk, appD. 

## ğŸ¥ Demo
ğŸ”— [Live Demo](#) (if applicable) 
ğŸ“¹ [Video Demo](#) (if applicable)  
ğŸ–¼ï¸ Screenshots:

![Screenshot 1](link-to-image)

## ğŸ’¡ Inspiration
Teams passion to work on AI/ML usecase. We would really want to help the platform support team and to increase their efficiency by providing them the integrated platform support tools as they are 1st line of defence and gaurdians to our application.

## âš™ï¸ What It Does
The creation of integrated tool is still in process.
Currently it provides an chatbot facility where the platform support team can provide the context of the issue which they gets notified through splunk, appD and can identify the cause of issue and possible resolutions.

## ğŸ› ï¸ How We Built It
Using Python and Google Gemini LLM to create a bot and gradio for UI

## ğŸš§ Challenges We Faced
Initially started with OpenAI models but ran into quota limits and then tried deepseek models, but finally landed on Gemini through which we are atleast able to interact with the model to get responses related to Production support issues.

## ğŸƒ How to Run
install python
install gradio
Get API key for invoking Google Gemini LLM
execute the python file which opens up the UI that interacts with LLM upon submission of query from user

## ğŸ—ï¸ Tech Stack
Python
Google Gemini LLM
Gradio for UI

## ğŸ‘¥ Team
Kiran Narkedamilli
Satish kottakota
Sadanand Maskale
Haribabu Narisetty
